{"title":"GPU硬件架构解析","uid":"e53b524540553e698f581f4943857291","slug":"GPU硬件架构解析","date":"2025-08-10T10:18:38.000Z","updated":"2025-08-10T10:21:36.612Z","comments":true,"path":"api/articles/GPU硬件架构解析.json","keywords":null,"cover":[],"content":"<h2 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h2><ul>\n<li><p>AI计算需求与硬件挑战</p>\n<p>当我尝试训练一个大模型时，通常会遇到两个挑战：</p>\n<ol>\n<li><p>这个模型能否在现有硬件环境中运行？</p>\n</li>\n<li><p>需要多长时间才能完成一个数据集的训练？</p>\n<p>这个两个挑战的核心也正式是大模型的扩展定律（Scaling Law）中提到的队模型表现的两个因素：模型规模和数据规模。</p>\n</li>\n</ol>\n<p>Scaling Law</p>\n<p>​    在 AI 模型的发展过程中，Scaling Law（扩展定律）成为推动性能提升的重要理论基础。根据 Scaling Law，当模型参数、训练数据和硬件配置同步增加时，AI 模型的能力会随之提升。</p>\n</li>\n</ul>\n<p>​       硬件挑战</p>\n<p>​        a. 摩尔定律增速放缓、晶体管尺寸物理极限、能耗不断增加。</p>\n<p>​\tb. 存储墙：存储器的数据访问速度跟不上计算处理速度。</p>\n<p>​\tc. 能耗墙：随着芯片性能的提升，能耗和散热问题成为限制进一步性能提升的主要因素。</p>\n<ul>\n<li><p>GPU在AI计算中的核心地位</p>\n</li>\n<li><p>本文架构解析思路</p>\n<p>主要从以下三个维度进行解析：</p>\n<ul>\n<li><p>系统维度<br> 硬件组件层 → 子系统层 → 系统层 → 集群层<br>  ↓                           ↓                   ↓               ↓<br> GPU核心          GPU模组   AI服务器   AI集群</p>\n</li>\n<li><p>性能维度</p>\n<p> 计算瓶颈 → 内存瓶颈 → 存储瓶颈 → 网络瓶颈<br> ↓                      ↓                    ↓                   ↓<br> GPU算力    内存带宽           存储IO    网络延迟<br> ↓                      ↓                    ↓                   ↓<br> FLOPS         带宽&#x2F;延迟          IOPS     吞吐量&#x2F;延迟</p>\n</li>\n<li><p>扩展维度</p>\n<p> 单GPU → 多GPU → 单节点 → 多节点 → 大规模集群<br>   ↓                   ↓               ↓                 ↓                 ↓<br> 计算密度  互联带宽  节点密度   网络带宽    系统规模</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"2-GPU核心架构\"><a href=\"#2-GPU核心架构\" class=\"headerlink\" title=\"2. GPU核心架构\"></a>2. GPU核心架构</h2><h3 id=\"2-1-单GPU内部结构\"><a href=\"#2-1-单GPU内部结构\" class=\"headerlink\" title=\"2.1 单GPU内部结构\"></a>2.1 单GPU内部结构</h3><ul>\n<li><p>计算单元 (CUDA核心、张量核心)</p>\n</li>\n<li><p>内存层次 (寄存器、共享内存、L2缓存、显存)</p>\n</li>\n<li><p>互联结构 (PCIe、NVLink)</p>\n</li>\n</ul>\n<h3 id=\"2-2-多GPU扩展方式\"><a href=\"#2-2-多GPU扩展方式\" class=\"headerlink\" title=\"2.2  多GPU扩展方式\"></a>2.2  多GPU扩展方式</h3><p>单卡GPU形态</p>\n<table>\n<thead>\n<tr>\n<th>形态</th>\n<th>规格</th>\n<th align=\"left\">版本演进</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PCIe卡</td>\n<td><img src=\"./Snipaste_2025-08-04_15-33-27.png\" style=\"zoom:40%;\" ></td>\n<td align=\"left\">全高全长FHFL</td>\n<td></td>\n</tr>\n<tr>\n<td>SXM卡</td>\n<td><img src=\"https://l4rz.net/running-nvidia-sxm-gpus-in-consumer-pcs/images/sxm4-vicor-preso.jpg\" style=\"zoom:25%;\" /></td>\n<td align=\"left\">SXM 1.0 Pascal <br>SXM 2.0 &amp; 3.0 Volta <br>SXM 4.0 Ampere <br>SXM 5.0 Hopper</td>\n<td><em>Server PCI Express Module</em></td>\n</tr>\n<tr>\n<td>OAM卡</td>\n<td><img src=\"/Users/rockyliu/Documents/Snipaste_2025-08-04_16-09-27.png\" style=\"zoom:45%;\" /></td>\n<td align=\"left\">OAM 1.0  2019.07.13<br>OAM 1.1 2020.07.22<br>OAM 1.5 2022.02.23<br>OAM 2.0 2023.09.14</td>\n<td><em>OCP Accelerator Module</em></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>单卡到多卡的技术路径</p>\n<p>常见三种GPU形态，但是在实际使用中很少出现单卡场景，通常搭配两卡、四卡及八卡使用；</p>\n<ul>\n<li><p>多卡物理形态</p>\n<table>\n<thead>\n<tr>\n<th>形态</th>\n<th>拓扑结构</th>\n<th>规格</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PCIe 多卡</td>\n<td></td>\n<td><img src=\"/Users/rockyliu/Documents/PCIe*8.png\" style=\"zoom:35%;\" /></td>\n<td></td>\n</tr>\n<tr>\n<td>HGX</td>\n<td><img src=\"/Users/rockyliu/Documents/HGX.png\" style=\"zoom:50%;\" /></td>\n<td><a href=\"https://www.nvidia.com/en-us/data-center/hgx/\">HGX-Platform</a> 8卡<img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/HGX_A100_8_way_3QTR_Front_Left-Edit-1-625x417.jpg\" style=\"zoom:45%;\" />&#x2F;&gt;</td>\n<td>该基板搭载：<br>i.8 &#x2F;4 个 NVIDIA GPU <br>ii.6 个 NVSwitch 节点。<br>(*Ps:*NVSwitch数量不固定)</td>\n</tr>\n<tr>\n<td>UBB</td>\n<td><img src=\"/Users/rockyliu/Documents/UBB8.png\" alt=\"image-20250804172853058\" style=\"zoom:20%;\" /></td>\n<td><img src=\"https://www.servethehome.com/wp-content/uploads/2025/06/AMD-Instinct-MI350X-UBB-8-GPU.jpg\" style=\"zoom:25%;\" /></td>\n<td><em>Universal Baseboard</em></td>\n</tr>\n</tbody></table>\n<p><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/HGX_A100_8_way_3QTR_Front_Left-Edit-1-625x417.jpg\">https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/HGX_A100_8_way_3QTR_Front_Left-Edit-1-625x417.jpg</a></p>\n<p>GPU集群拓扑结构</p>\n</li>\n</ul>\n</li>\n<li><p>带宽与延迟挑战</p>\n</li>\n</ul>\n<h2 id=\"3-AI服务器系统架构\"><a href=\"#3-AI服务器系统架构\" class=\"headerlink\" title=\"3. AI服务器系统架构\"></a>3. AI服务器系统架构</h2><h3 id=\"3-1-硬件组件组成\"><a href=\"#3-1-硬件组件组成\" class=\"headerlink\" title=\"3.1 硬件组件组成\"></a>3.1 硬件组件组成</h3><ul>\n<li><p>CPU与系统内存</p>\n</li>\n<li><p>GPU模组与显存</p>\n</li>\n<li><p>存储系统 (NVMe SSD)</p>\n</li>\n<li><p>网络接口 (InfiniBand&#x2F;RoCE)</p>\n</li>\n</ul>\n<h3 id=\"3-2-互联技术对比\"><a href=\"#3-2-互联技术对比\" class=\"headerlink\" title=\"3.2 互联技术对比\"></a>3.2 互联技术对比</h3><ul>\n<li><p>PCIe vs NVLink vs InfiniBand</p>\n</li>\n<li><p>GPU Direct RDMA技术</p>\n</li>\n<li><p>数据传输优化策略</p>\n</li>\n</ul>\n<h2 id=\"4-服务器形态与部署\"><a href=\"#4-服务器形态与部署\" class=\"headerlink\" title=\"4. 服务器形态与部署\"></a>4. 服务器形态与部署</h2><h3 id=\"4-1-服务器类型\"><a href=\"#4-1-服务器类型\" class=\"headerlink\" title=\"4.1 服务器类型\"></a>4.1 服务器类型</h3><ul>\n<li><p>紧耦合型 (DGX系列)</p>\n</li>\n<li><p>模块化型 (OAM&#x2F;OCP标准)</p>\n</li>\n<li><p>定制化解决方案</p>\n</li>\n</ul>\n<h3 id=\"4-2-散热与电源\"><a href=\"#4-2-散热与电源\" class=\"headerlink\" title=\"4.2 散热与电源\"></a>4.2 散热与电源</h3><ul>\n<li><p>风冷 vs 液冷方案</p>\n</li>\n<li><p>高密度GPU的散热挑战</p>\n</li>\n<li><p>电源管理与能效优化</p>\n</li>\n</ul>\n<h2 id=\"5-性能优化策略\"><a href=\"#5-性能优化策略\" class=\"headerlink\" title=\"5. 性能优化策略\"></a>5. 性能优化策略</h2><h3 id=\"5-1-内存优化\"><a href=\"#5-1-内存优化\" class=\"headerlink\" title=\"5.1 内存优化\"></a>5.1 内存优化</h3><ul>\n<li><p>HBM vs GDDR显存选择</p>\n</li>\n<li><p>显存容量与带宽平衡</p>\n</li>\n<li><p>大模型训练的内存策略</p>\n</li>\n</ul>\n<h3 id=\"5-2-存储优化\"><a href=\"#5-2-存储优化\" class=\"headerlink\" title=\"5.2 存储优化\"></a>5.2 存储优化</h3><ul>\n<li><p>GPU Direct Storage技术</p>\n</li>\n<li><p>NVMe存储直通</p>\n</li>\n<li><p>数据加载性能优化</p>\n</li>\n</ul>\n<h2 id=\"6-发展趋势与展望\"><a href=\"#6-发展趋势与展望\" class=\"headerlink\" title=\"6. 发展趋势与展望\"></a>6. 发展趋势与展望</h2><h3 id=\"6-1-技术演进方向\"><a href=\"#6-1-技术演进方向\" class=\"headerlink\" title=\"6.1 技术演进方向\"></a>6.1 技术演进方向</h3><ul>\n<li><p>计算密度持续提升</p>\n</li>\n<li><p>互联带宽不断增长</p>\n</li>\n<li><p>异构计算加速器整合</p>\n</li>\n</ul>\n<h3 id=\"6-2-新兴技术影响\"><a href=\"#6-2-新兴技术影响\" class=\"headerlink\" title=\"6.2 新兴技术影响\"></a>6.2 新兴技术影响</h3><ul>\n<li><p>存储-计算融合架构</p>\n</li>\n<li><p>近数据计算技术</p>\n</li>\n<li><p>未来AI硬件发展方向</p>\n</li>\n</ul>\n<h2 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a>7. 总结</h2><ul>\n<li><p>AI服务器架构设计要点</p>\n</li>\n<li><p>性能瓶颈与优化方向</p>\n</li>\n<li><p>技术选型建议</p>\n</li>\n</ul>\n","feature":true,"text":"1. 引言 AI计算需求与硬件挑战 当我尝试训练一个大模型时，通常会遇到两个挑战： 这个模型能否在现有硬件环境中运行？ 需要多长时间才能完成一个数据集的训练？ ...","permalink":"/post/GPU硬件架构解析","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E5%BC%95%E8%A8%80\"><span class=\"toc-text\">1. 引言</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-GPU%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">2. GPU核心架构</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-1-%E5%8D%95GPU%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">2.1 单GPU内部结构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-2-%E5%A4%9AGPU%E6%89%A9%E5%B1%95%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">2.2  多GPU扩展方式</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-AI%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">3. AI服务器系统架构</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-1-%E7%A1%AC%E4%BB%B6%E7%BB%84%E4%BB%B6%E7%BB%84%E6%88%90\"><span class=\"toc-text\">3.1 硬件组件组成</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-2-%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">3.2 互联技术对比</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BD%A2%E6%80%81%E4%B8%8E%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">4. 服务器形态与部署</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">4.1 服务器类型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-2-%E6%95%A3%E7%83%AD%E4%B8%8E%E7%94%B5%E6%BA%90\"><span class=\"toc-text\">4.2 散热与电源</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">5. 性能优化策略</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">5.1 内存优化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-2-%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">5.2 存储优化</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF%E4%B8%8E%E5%B1%95%E6%9C%9B\"><span class=\"toc-text\">6. 发展趋势与展望</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-1-%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E6%96%B9%E5%90%91\"><span class=\"toc-text\">6.1 技术演进方向</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-%E6%96%B0%E5%85%B4%E6%8A%80%E6%9C%AF%E5%BD%B1%E5%93%8D\"><span class=\"toc-text\">6.2 新兴技术影响</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#7-%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">7. 总结</span></a></li></ol>","author":{"name":"Rocky Liu","slug":"blog-author","avatar":"https://raw.githubusercontent.com/rocky-lmg/Picture-Bed/master/img/blog-avatar.png","link":"/","description":"暂时没想好","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"GPU性能分析","uid":"e00aae84c93424a8228795810f78a12d","slug":"GPU性能分析","date":"2025-08-25T13:34:03.000Z","updated":"2025-08-25T13:34:03.296Z","comments":true,"path":"api/articles/GPU性能分析.json","keywords":null,"cover":null,"text":"","permalink":"/post/GPU性能分析","photos":[],"count_time":{"symbolsCount":0,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Rocky Liu","slug":"blog-author","avatar":"https://raw.githubusercontent.com/rocky-lmg/Picture-Bed/master/img/blog-avatar.png","link":"/","description":"暂时没想好","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"CPU硬件架构解析","uid":"fd66792a70b4a45f7bd145438a8832e0","slug":"CPU硬件架构解析","date":"2025-08-10T10:18:29.000Z","updated":"2025-08-10T10:22:30.725Z","comments":true,"path":"api/articles/CPU硬件架构解析.json","keywords":null,"cover":[],"text":"1.引言《Processor Microarchitecture An Implementation Perspective》 链接：https://dl.ic...","permalink":"/post/CPU硬件架构解析","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[],"tags":[],"author":{"name":"Rocky Liu","slug":"blog-author","avatar":"https://raw.githubusercontent.com/rocky-lmg/Picture-Bed/master/img/blog-avatar.png","link":"/","description":"暂时没想好","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}