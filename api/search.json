[{"id":"29cb7deec167cd38de08f4c215d6b393","title":"重新开始","content":"","slug":"重新开始","date":"2026-01-27T16:30:32.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"e00aae84c93424a8228795810f78a12d","title":"GPU性能分析","content":"","slug":"GPU性能分析","date":"2025-08-25T13:34:03.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"e53b524540553e698f581f4943857291","title":"GPU硬件架构解析","content":"1. 引言\nAI计算需求与硬件挑战\n当我尝试训练一个大模型时，通常会遇到两个挑战：\n\n这个模型能否在现有硬件环境中运行？\n\n需要多长时间才能完成一个数据集的训练？\n这个两个挑战的核心也正式是大模型的扩展定律（Scaling Law）中提到的队模型表现的两个因素：模型规模和数据规模。\n\n\nScaling Law\n​    在 AI 模型的发展过程中，Scaling Law（扩展定律）成为推动性能提升的重要理论基础。根据 Scaling Law，当模型参数、训练数据和硬件配置同步增加时，AI 模型的能力会随之提升。\n\n\n​       硬件挑战\n​        a. 摩尔定律增速放缓、晶体管尺寸物理极限、能耗不断增加。\n​\tb. 存储墙：存储器的数据访问速度跟不上计算处理速度。\n​\tc. 能耗墙：随着芯片性能的提升，能耗和散热问题成为限制进一步性能提升的主要因素。\n\nGPU在AI计算中的核心地位\n\n本文架构解析思路\n主要从以下三个维度进行解析：\n\n系统维度 硬件组件层 → 子系统层 → 系统层 → 集群层  ↓                           ↓                   ↓               ↓ GPU核心          GPU模组   AI服务器   AI集群\n\n性能维度\n 计算瓶颈 → 内存瓶颈 → 存储瓶颈 → 网络瓶颈 ↓                      ↓                    ↓                   ↓ GPU算力    内存带宽           存储IO    网络延迟 ↓                      ↓                    ↓                   ↓ FLOPS         带宽&#x2F;延迟          IOPS     吞吐量&#x2F;延迟\n\n扩展维度\n 单GPU → 多GPU → 单节点 → 多节点 → 大规模集群   ↓                   ↓               ↓                 ↓                 ↓ 计算密度  互联带宽  节点密度   网络带宽    系统规模\n\n\n\n\n2. GPU核心架构2.1 单GPU内部结构\n计算单元 (CUDA核心、张量核心)\n\n内存层次 (寄存器、共享内存、L2缓存、显存)\n\n互联结构 (PCIe、NVLink)\n\n\n2.2  多GPU扩展方式单卡GPU形态\n\n\n\n形态\n规格\n版本演进\n备注\n\n\n\nPCIe卡\n\n全高全长FHFL\n\n\n\nSXM卡\n\nSXM 1.0 Pascal SXM 2.0 &amp; 3.0 Volta SXM 4.0 Ampere SXM 5.0 Hopper\nServer PCI Express Module\n\n\nOAM卡\n\nOAM 1.0  2019.07.13OAM 1.1 2020.07.22OAM 1.5 2022.02.23OAM 2.0 2023.09.14\nOCP Accelerator Module\n\n\n\n单卡到多卡的技术路径\n常见三种GPU形态，但是在实际使用中很少出现单卡场景，通常搭配两卡、四卡及八卡使用；\n\n多卡物理形态\n\n\n\n形态\n拓扑结构\n规格\n描述\n\n\n\nPCIe 多卡\n\n\n\n\n\nHGX\n\nHGX-Platform 8卡&#x2F;&gt;\n该基板搭载：i.8 &#x2F;4 个 NVIDIA GPU ii.6 个 NVSwitch 节点。(*Ps:*NVSwitch数量不固定)\n\n\nUBB\n\n\nUniversal Baseboard\n\n\nhttps://developer-blogs.nvidia.com/wp-content/uploads/2020/05/HGX_A100_8_way_3QTR_Front_Left-Edit-1-625x417.jpg\nGPU集群拓扑结构\n\n\n\n带宽与延迟挑战\n\n\n3. AI服务器系统架构3.1 硬件组件组成\nCPU与系统内存\n\nGPU模组与显存\n\n存储系统 (NVMe SSD)\n\n网络接口 (InfiniBand&#x2F;RoCE)\n\n\n3.2 互联技术对比\nPCIe vs NVLink vs InfiniBand\n\nGPU Direct RDMA技术\n\n数据传输优化策略\n\n\n4. 服务器形态与部署4.1 服务器类型\n紧耦合型 (DGX系列)\n\n模块化型 (OAM&#x2F;OCP标准)\n\n定制化解决方案\n\n\n4.2 散热与电源\n风冷 vs 液冷方案\n\n高密度GPU的散热挑战\n\n电源管理与能效优化\n\n\n5. 性能优化策略5.1 内存优化\nHBM vs GDDR显存选择\n\n显存容量与带宽平衡\n\n大模型训练的内存策略\n\n\n5.2 存储优化\nGPU Direct Storage技术\n\nNVMe存储直通\n\n数据加载性能优化\n\n\n6. 发展趋势与展望6.1 技术演进方向\n计算密度持续提升\n\n互联带宽不断增长\n\n异构计算加速器整合\n\n\n6.2 新兴技术影响\n存储-计算融合架构\n\n近数据计算技术\n\n未来AI硬件发展方向\n\n\n7. 总结\nAI服务器架构设计要点\n\n性能瓶颈与优化方向\n\n技术选型建议\n\n\n","slug":"GPU硬件架构解析","date":"2025-08-10T10:18:38.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"fd66792a70b4a45f7bd145438a8832e0","title":"CPU硬件架构解析","content":"1.引言《Processor Microarchitecture An Implementation Perspective》\n链接：https://dl.icdst.org/pdfs/files/15b09def448c317556dc0fc412aee571.pdf\n处理器微架构演进主要源自两个因素：\n\ntechnology scaling\n\nworkload evolution\n\n\n###1.1 Moore’s Law\n\nMoore, Gordon E. (1965). “Cramming more components onto integrated circuits” (PDF). Electronics Magazine. pp. 4.\n“The complexity for minimum component costs has increased at a rate of roughly a factor of two per year.”\nMoore refined it to “every two years” in 1975\nAlso quoted as “every 18 months” by David House, (referring to performance)\nMost popular formulation: #transistors&#x2F;IC\n\n\nCarver Mead coined it as Moore’s law around 1970\n– “Tall &amp; Thin engineers”\n\n\nUltimate limit of Moore’s Law\nNo one knows\nHow to use the capability? Resource limit?\n\n\n\n1.2 CPU微体系结构1.2.1 微架构分类按照一些相互正交的维度进行分类：\n\nPipelined&#x2F;Nonpipelined Processors\nPipelined提高了ILP，并且由于成本效益好，几乎所有的处理器都采用\n\nIn-Order&#x2F;Out-of-Order Processors\nOut-of-Order 需要更复杂的硬件设计，在乱序执行中，指令可以不按程序指定的顺序执行，减少阻塞，但对外表现的行为还是和顺序执行的处理器一样；\n\nScalar&#x2F;Superscalar Processors \n标量和超标量处理器，标量处理器的 IPC 最多为 1，因为只有一套执行单元，而不是标量处理器的就是超标量处理器，IPC 可以大于 1。\n\nVector Processors\n向量处理器可以使用一条向量指令处理多个元素的向量，也就是 SIMD，例如 Intel 的 AVX 指令就是 SIMD 指令；\n\nMulticore Processors\n是否多核？多核处理器中每一个核心的硬件资源相对独立不共享\n\nMultithreaded Processors\n是否多线程？多线程中的线程通常共用大部分的硬件资源\n\n\n流水线技术\n![image-20250724163845529](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250724163845529.png)\n一条指令的生命周期分为五个阶段：\n取指（IF）——&gt;译码（ID）——&gt;重命名 &amp; 分发——&gt;执行（EXE）——&gt;访存（MEM）——&gt;写回（WB）\n《从入门到放弃：CPU流水线技术全解析》https://juejin.cn/post/7401417746541068297\n将访存单独作为一个阶段的考虑：\n\n假设访存延迟为0周期，即理想寄存器\n\n地址计算（加法器）的路径和访存路径加起来太长\n\n拆分为两个阶段更均衡\n\n但在实际的处理器设计中, 上述假设不再成立\n访存操作一般需要多个周期；\ncache: 缓存的控制逻辑是个状态机；即使命中，状态机也需要经过若干个周期的控制才能读出数据\n访存路径上有很多地址寄存器，地址计算的延迟和资源开销并不明显\n\n\nhttps://xiaofeng.info//presentations/history_Intel_CPU.pdf\nhttps://www.agner.org/optimize/microarchitecture.pdf\nhttps://www.mindshare.com/eLearning/Course/Intel_x86_Processor_and_Platform_Architecture_eLearning_Course\n• Intel x86 CPU and Chipset Evolution• Current Core and Xeon CPUs: Ice Lake, Cascade Lake, plus “Refresh” Variants• X86 Instruction Set Architecture (ISA) and CPU Operating Modes• Core and Xeon CPU Microarchitecture Differences• Caches• Platform Addressing• Main Memory DRAM• Ultra Path Interconnect (UPI)• CPU Integrated Graphics• CPU Integrated IO (IIO)• Interrupt Handling• Hardware Virtualization Support• Platform Controller Hub (PCH) Features• Power and Thermal Management• CPU Performance Monitoring\nhttps://cdrdv2-public.intel.com/786255/786255_330119_ia-introduction-basics-paper.pdf\nhttps://www.mindshare.com/files/ebooks/x86%20instruction%20set%20architecture.pdf\n2.X862.1 Intel2.1.1 产品路标演进Intel x86 Core and Xeon Platform Backgroundo Intel 64 and IA-32 CPU lineage§ 80386 to Ice Lake&#x2F;Cascade Lake§ Core and Xeon CPUs Expected Nexto Ice Lake&#x2F;Cascade Lake Platform Examples§ Gaming Desktop§ 2-in-1 Laptop§ Xeon Scalable CPU Server\nX86 Instruction Set Architecture (ISA)o CPU Core Fetch&#x2F;Decode&#x2F;Execute Roleo X86 Instruction Basicso Instruction Set Overview§ General Purpose Instructions§ Floating Point and SIMD Instructions§ Program Flow Instructions§ Hardware-Related Instructionso X86 Register Set Overview§ General Purpose Registers (GPRs)§ X87&#x2F;MMX Registers§ XMM&#x2F;YMM&#x2F;ZMM Registers§ Segmentation Registers§ Control Registers§ Debug Registers§ Model-Specific Registers (MSRs)o X86 CPU Operating Modes§ Real Mode§ Protected Mode§ Virtual-8086 Mode§ System-Management Mode (SMM)§ IA32e (Long) Mode\n![image-20250724114810496](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250724114810496.png)\n典型的Dual-socket systems\n\n2.1.2 NUMA 架构Uniform Memory Access Domain\n\n Sub-NUMA Clustering\n\n​                       Figure 2 – Block Diagram Representing Domains Of sub-NUMA With Two Clusters\n\n​                         Figure 3 – Block Diagram Representing Domains Of sub-NUMA With Four Clusters\n2.2 AMD2.2.1 架构演进![AMD CPU架构](&#x2F;Users&#x2F;rockyliu&#x2F;Documents&#x2F;技术宝典&#x2F;CPU&#x2F;X86&#x2F;AMD CPU架构.png)\nAMD EPYC 9004系列\n![image-20250723150813290](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250723150813290.png)\n\n 5TH GEN AMD EPYC™ PROCESSOR ARCHITECTURE\nhttps://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/white-papers/5th-gen-amd-epyc-processor-architecture-white-paper.pdf I&#x2F;O DIE FEATURES\n![AMD-I:O die](&#x2F;Users&#x2F;rockyliu&#x2F;Documents&#x2F;技术宝典&#x2F;CPU&#x2F;X86&#x2F;AMD-I:O die.png)\nWhen three links between processors are used, an additional 16 PCIe lanes on each CPU are available for general I&#x2F;O, bringing the total I&#x2F;O capacity up to 160 lanes. When four links are configured, they can support a maximum theoretical bandwidth of 512 GB&#x2F;s between processors.\n\n当双路CPU使用G-links * 3 （48 Lanes）时，另外的16 PCIe lanes 可以用于标准I&#x2F;O，总的I&#x2F;O能力扩展到160 lanes;\n当双路CPU使用G-links * 4 （64 Lanes）时，CPU间支持最大双向理论带宽512GB&#x2F;s。\n\n\nNon-Uniform Memory Access (NUMA) architecture \n\nDifferent latencies\n\n​       depending on the proximity of a processor core to memory and I&#x2F;O controllers\n\nSame NUMA node provides uniform good performance,while use resources in differing nodes increases latencies.\n\nNUMA Setting \nNUMA Nodes Per Socket (NPSx)• NPS4: Four NUMA nodes per socket, one per quadrant.  o Requires symmetrical CCD configuration across all quadrants of the SoC.  o Preferred Interleaving: 2-channel interleaving using channels from each quadrant.• NPS2: Two NUMA nodes per socket, one per left&#x2F;right half of the SoC.  o Requires symmetrical CCD configuration across left&#x2F;right halves of the SoC.  o Preferred Interleaving: 4-channel interleaving using channels from each half.• NPS1: One NUMA node per socket.  o Available for any CCD configuration in the SoC.  o Preferred Interleaving: 8-channel interleaving using all channels in the socket.• NPS0: One NUMA node per system.  o Available only on a 2P system.  o Preferred Interleaving: 16-channel interleaving using all channels in the system.Note: If the CCD configuration is altered by software (e.g., BIOS Setup Option), NPS4 and NSP2options may not be available based on the Symmetry requirements noted above.\n\n![image-20250723175300806](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250723175300806.png)\n![image-20250723175400320](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250723175400320.png)\n![image-20250723175602458](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250723175602458.png)\n![image-20250723175515519](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250723175515519.png)\n引发问题？\n   1.NUMA是个好东西，为啥有的业务场景抗拒开启NPS？\n\n跨NUMA分配CPU导致远程访问性能损耗，出现性能分层\n\n不同业务间共享核导致Cache频繁加载、互相污染开销增加，可用性和延时增加\n\n不同优先级和不同资源敏感程度 业务pod在节点上数量分配不均衡，导致竞争开销\n\n节点上其他资源的竞争（IO、网络、内存）\n 2.开启NPS后会增加Latency,会造成哪些影响？如何进行性能调优？\n\n\nInfinity Fabric links\n External Global Memory Interconnect [xGMI] links \n\nDual-socket systems\n\n​       4 xGMI ：4x16&#x3D;64 PCIe lanes from each socket for Infinity Fabric connections.  leave 64 PCIe lanes each socket&#x3D; 64x2&#x3D;128 lanes \n​       3 xGMI :  In these cases, 160 lanes for PCIe (80 per socket) \n2.3 Chiplet技术​\tChiplet 即小芯粒，它将一类满足特定功能的 die（裸片），通过 die-to-die 内部互联技术将多个模块芯片与底层基础芯片封装在一起，形成一个系统芯片。\n\n\n\n大面积芯片降低成本提升良率\n随着先进制程推进，研发成本持续走高。Chiplet 将单颗 SOC 的不同功能模块拆分成独立的小芯粒（即 Chiplet）， 大大缩小了单颗 die 的面积，起到提升良率、降低成本的作用。\n\n小芯片模块化，实现IP复用，加速芯片迭代\n\nDie to die的高速互联（载板或者Interposer互联）“堆料“\nInterposer 的材质又分为硅基、有机两种。若芯片是平铺在 封装的衬底上，则称为 2.5D 封装，若是芯片之间堆叠封装，则称为 3D 封装。\n![image-20250805145518266](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;2.5D:3D封装.png)\n芯片厂可以将多颗计算核心die进行合封，提高芯片整体性能。\n\n\n3.ARM3.1 硬件架构《Kunpeng 920: The First 7-nm Chiplet-Based 64-Core ARM SoC for Cloud Services》\n链接：https://ieeexplore.ieee.org/document/9444893\n知乎解读：https://zhuanlan.zhihu.com/p/654058158\nKunpeng 920 采用乐高式架构设计。\n![image-20250725160244189](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725160244189.png)\n双路使用huawei的Hydra，接口提供24-lane的SerDes\n![image-20250725160326915](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725160326915.png)\n3.1.1 芯片组件![image-20250724201151569](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250724201151569.png)\n3.1.2 组件单元\n片上总线：Cache一致性总线 Hydra接口级联\n\nCCL：内核集群\n华为鲲鹏920的每个内核集群（CCL）都由4个内核和专用L2 Cache组成。华为鲲鹏920的CCL之间支持完全一致性。总线上的其他功能单元可以一致性地访问每个CCL的缓存中的最新数据。\n\n\n![image-20250725151018554](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725151018554.png)\n\nICL：I&#x2F;O集群\n\n![image-20250725151216449](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725151216449.png)\n一个典型的ICL包括以下组成部分：\n\n多个设备（如图2-9所示）；\n0个或1个SMMU（System Memory Management System），为设备提供地址转换和访问保护功能；\n1个系统总线接口\n1个Sysctrl或Subctrl，用于固件初始化和公共配置；\n1个Dispatch，为访问设备寄存器空间提供物理地址（PA）译码；\n0个或多个Scheduler，当设备数量较多时，Scheduler可以合并各设备的内存访问流量。\n\n\nSCCL：超级内核集群\n华为鲲鹏920的每个SCCL包括6个CCL、2个ICL和4个DDR控制器。DDR控制器也可以看做一个设备。SCCL内部结构如图2-10所示。\n![image-20250725152900850](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725152900850.png)\n\nSICL：供超级I&#x2F;O集群\n每个SICL由4个ICL、1个Hydra接口和1个独立的IMU组成。\n![image-20250725152955168](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725152955168.png)\n\n\n3.2 内存子系统\n![image-20250725153128420](&#x2F;Users&#x2F;rockyliu&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20250725153128420.png)\n4.性能分析4.1 前置知识\n熟悉CPU硬件，关注微架构级别的硬件演进和主流CPU演进：\na. X86 (Intel &amp; AMD)、ARM（Kunpeng）等主流CPU厂商产品：\ni. 基本参数\n ii. 微架构设计 \niii. 各级（core、uncle、offcore）PMC含义、获取和应用方式（关键指标计算）\nb. CPU体系结构\ni. CPU流水线技术\nii. 理解CPU的页表机制、预取机制；\niii. 流水线+超标量+多发射技术如何并行执行指令提高效率\niv. 理解分支预测、\nv. 内存组件的技术细节\nvi. PCIe组件技术细节\n\n了解Linux内核个和相应分析工具\na.熟悉Linux 进程和线程管理和调度\nb. 掌握Linux的性能分析与调优方法，能够进行函数级问题定位；\ni. 熟练使用 FlameGraph、perf、Prometheus等工具；\nii. Pstack.      Gdb  attach \niii. Ebpf工具、bpftrace 进行内核路径trace\n\n了解公司业务的性能画像,能够通过Specint等Benchmark评估硬件性能：\na. 熟悉各类服务器性能指标的含义和获取方式,并据此评估业务性能需求；\ni. 硬件上:CPU利用率、IPC、各级cache&#x2F;TLBmiss率、branch和branchmiss数、内存占用、内存带宽、内存延迟、UPI&#x2F;xGMI带宽、TMA指标、网卡带宽;\nii. 软件上:CPUuser&#x2F;sys&#x2F;软&#x2F;硬中断利用率占比、整机load、网卡丢包、上下文切换次数;\nb.理解各项基本单元测试的目的、方法,能够正确评估测试结果反映的性能水平：\n  i. 不同读写比例下的随机读写内存带宽-时延曲线;\n  ii. 原子操作的指令开销;\n  iii .Specint的各子项负载的工作pattern和性能需求;\nc.掌握常见性能优化方式,帮助提高业务性能:\n  i. 正确使用大页内存、透明大页;\n  ii. 合理绑核,合理配置实例线程数量&#x2F;内存大小;\n  iii. 正确配置网络相关参数(网卡队列数量、大小、中断绑核、网卡PCle配置);\n\n\n4.2 分析思路木桶效应\n首先要识别性能瓶颈，通过监控测量分析定位性能瓶颈，才能结合场景对症下药（理解工作原理）\n在分析过程中要明确关注哪些性能指标，这个是性能分析的关键：\n\n微架构分析Microarchitecture analysis ：CPU内部瓶颈（bottlenecks）\n\n锁分析Lock analysis：锁竞争和等待时间\n\nIO分析：IO操作瓶颈\n\n调度分析：由于调度产生的瓶颈\n\nCPU限制分析：识别由于CPU竞争导致的瓶颈\n\n内存边界分析：内存碎片、内存总线限制\n\n\n微架构分析：\n​\t现代CPU通常采用五级流水，通常包含五个执行阶段。每条指令可以分解为与流水线阶段对应的微操作：IF、ID、EXEC、MEM 和 WB。\n\n可以使用perf stat命令来检查：\n\n每个指令周期的指令数越多，应用程序可以完成的工作就越多。\n​\t\nCPU数据缓存分析\nCPU数据缓存分析可以通过perf stat -e L1-dcache-load-misses,L1-dcache-loads来验证。\nCPU分支预测分析\nCPU 分支预测的指标可以通过 来检查perf stat -e branches,branch-misses\nTLB 缓存和 FLOPS 是潜在的瓶颈。CPU 通常将虚拟地址到物理地址的转换缓存在 TLB 中。当 TLB 缓存未命中时，CPU 需要遍历内核页表，根据引用的虚拟地址计算物理地址。这个过程非常耗时。使用大页可以减轻 TLB 的压力。\nFlame graphs 火焰图 \nIPC和CPU频率的关系\n由于 IPC是衡量微架构性能优劣的指标\n内存密集型应用程序通常以低 IPC (0-1) 为特征，而计算密集型工作负载往往具有高 IPC (4-6)。\nLinux perf 用户可以通过运行以下命令测量其工作负载的 IPC：\n12345$ perf stat -e cycles,instructions -- a.exe2369632 cycles1725916 instructions # 0,73 insn per cycle# 或更简单地:$ perf stat ./a.exe\n\n\n\n\n\n\n\n问题：\n1.CPU核心时钟和参考时钟的区别？\n2.当你提高频率时， IPC（每个周期内的指令数）是上升、下降还是保持不变？\n3.Roofline 性能模型是一个以吞吐量为导向的性能模型\n硬件有两个主要限制：计算速度 (峰值计算性能， FLOPS) 和数据移动速度 (峰值内存带宽， GB&#x2F;s)。\n算术强度 (Arithmetic Intensity, AI) 是 FLOPS 和字节之间的比率\n\n\n图 中的 roofline 图将两个应用程序 A 和 B 的性能与硬件限制进行了对比。应用程序 A 的运算强度较低，其性能受内存带宽限制，应用程序 B 的计算密集型程度更高，因此不会受到内存瓶颈的太大影响。\n5.参考文献1.CPU Performance Analysis\n2.《Performance Analysis and Tuning on Modern CPU》\n","slug":"CPU硬件架构解析","date":"2025-08-10T10:18:29.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"845ab074e0d1510ac721db20b5992295","title":"宕机故障诊断","content":"","slug":"宕机故障诊断","date":"2025-08-10T08:13:08.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"56654ac3979c71635455fa5e3f557f97","title":"服务器测试一本通","content":"服务器测试一本通1. 前言1.1 编写目的​\t本文件旨在为服务器整机系统测试提供系统化、标准化的测试指导和操作规范。通过明确各部件及整机维度的测试内容、方法和要求，确保服务器产品在出厂前能够全面、有效地验证其功能、性能、稳定性、兼容性和安全性，提升产品质量，降低售后风险，为研发、测试及运维等相关人员提供权威的参考依据。\n1.2 适用范围​\t本文件适用于所有型号服务器产品的整机系统测试，包括但不限于X86、ARM等不同架构的服务器。适用对象涵盖服务器研发、测试、生产、质量管理等相关部门，适用于新产品开发、批量生产、版本升级及定制化项目的系统级测试工作。\n1.3 参考标准与文档\n《GB&#x2F;T 20273-2006 信息技术 服务器通用规范》\n《GB&#x2F;T 28181-2016 信息安全技术 网络和终端设备通用要求》\n《ISO&#x2F;IEC 9126 软件工程 产品质量》\n《SPEC CPU Benchmark Documentation》\n《JEDEC DDR5 SDRAM 标准》\n公司内部《服务器硬件测试规范》\n公司内部《服务器生产测试流程》\n相关操作系统及硬件厂商官方文档（如 Intel、AMD、ARM、RedHat、openEuler 等）\n\n2. 测试环境准备2.1 硬件环境2.2 软件环境2.3 测试工具与脚本2.4 测试前置条件3.部件维度测试3.1 CPU处理器3.1.1 识别与信息检测\n测试目的：验证操作系统和硬件管理工具能否正确识别CPU的型号、核心数、线程数、频率、缓存等关键信息。\n测试方法：\n\n\n在操作系统下使用命令查看CPU信息。\n通过BMC&#x2F;IPMI Web界面或命令行工具查看CPU信息。\n在BIOS&#x2F;UEFI中查看CPU信息。\n\n\n测试工具：lscpu、cat &#x2F;proc&#x2F;cpuinfo、dmidecode、ipmitool。\n预期结果：各工具显示的信息与CPU硬件规格一致，无识别错误或信息缺失。\n\n3.1.2 多核&#x2F;多线程功能\n测试目的：验证所有CPU核心和线程均能被操作系统正常调度和使用。\n测试方法：\n\n\n运行多线程压力测试，观察所有核心是否都被激活。\n使用任务管理器或性能监控工具查看各核心的使用率。\n将进程绑定到特定核心上运行，验证其功能。\n\n\n测试工具：stress-ng、taskset、htop。\n预期结果：所有核心和线程均能被正常调度，负载能够均匀或按需分配到各个核心。\n\n3.1.3 性能测试\n测试目的：评估CPU的计算性能，包括整数&#x2F;浮点运算、加密&#x2F;解密、压缩&#x2F;解压缩等能力，并与基准值或同类产品进行对比。\n\n测试方法：\n\n运行标准的CPU基准测试程序。\n模拟真实应用场景进行性能评估。\n\n\n测试工具：SPEC CPU® 2017 benchmarkSpec2017介绍：官网：https://www.spec.org/cpu2017/SPECCPU是一套行业标准的CPU密集型基准测试套件，其性能分数和处理器计算能力、内存能力和编译器强相关。Spec2017 是 Spec2006的演进版本，Spec2006当前已停止维护。Spec2017上的测试子项做了很多变动，其中rate和speed不再复用同一个二进制文件，并且speed中支持了多线程，不仅只使用单核。1.Benchmark子项按照计算类别分为int整型计算和fp浮点计算，int包含包括rate多任务计算性能和speed单任务计算性能，其中intrate&#x2F;intspeed包括10个测试子项，fprate包括17个测试子项，fpspeed包含10个测试子项。\n\nint 整形\n\n\n\n\nintrate子项\nintspeed子项\n语言\n子项描述\n备注\n\n\n\n500.perlbench_r\n600.perlbench_s\nC\nPerl interpreter\nPerl解释器\n\n\n502.gcc_r\n602.gcc_s\nC\nGNU C compiler\nGNU C编译器\n\n\n505.mcf_r\n605.mcf_s\nC\nRoute planning\n路由规划\n\n\n520.omnetpp_r\n620.omnetpp_s\nC++\nDiscrete Event simulation - computer network\n离散事件仿真-计算机网络\n\n\n523.xalancbmk_r\n623.xalancbmk_s\nC++\nXML to HTML conversion via XSLT\n通过XSLT将XML转换为HTML\n\n\n525.x264_r\n625.x264_s\nC\nVideo compression\n视频压缩\n\n\n531.deepsjeng_r\n631.deepsjeng_s\nC++\nArtificial Intelligence: alpha-beta tree search (Chess)\n人工智能：阿尔法-贝塔树搜索（国际象棋）\n\n\n541.leela_r\n641.leela_s\nC++\nArtificial Intelligence: Monte Carlo tree search (Go)\n人工智能：蒙特卡洛树搜索(Go)\n\n\n548.exchange2_r\n648.exchange2_s\nFortran\nArtificial Intelligence: recursive solution generator (Sudoku)\n人工智能：递归解生成器（数独）\n\n\n557.xz_r\n657.xz_s\nC\nGeneral data compression\n通用数据压缩\n\n\n\nfp 浮点型\n\n\n\n\nfprate子项\nfpspeed子项\n语言\n子项描述\n备注\n\n\n\n503.bwaves_r\n603.bwaves_s\nFortran\nExplosion modeling\n爆炸建模\n\n\n507.cactuBSSN_r\n607.cactuBSSN_s\nC++, C, Fortran\nPhysics: relativity\n物理学：相对论\n\n\n508.namd_r\n\nC++\nMolecular dynamics\n分子动力学\n\n\n510.parest_r\n\nC++\nBiomedical imaging: optical tomography with finite elements\n生物医学成像：有限元光学层析成像\n\n\n511.povray_r\n\nC++, C\nRay tracing\n光线追踪\n\n\n519.lbm_r\n619.lbm_s\nC\nFluid dynamics\n流体动力学\n\n\n521.wrf_r\n621.wrf_s\nFortran, C\nWeather forecasting\n天气预报\n\n\n526.blender_r\n\nC++, C\n3D rendering and animation\n3D渲染和动画\n\n\n527.cam4_r\n627.cam4_s\nFortran, C\nAtmosphere modeling\n大气建模\n\n\n\n628.pop2_s\nFortran, C\nWide-scale ocean modeling (climate level)\n大尺度海洋建模（气候水平）\n\n\n538.imagick_r\n638.imagick_s\nC\nImage manipulation\n图像处理\n\n\n544.nab_r\n644.nab_s\nC\nMolecular dynamics\n分子动力学\n\n\n549.fotonik3d_r\n649.fotonik3d_s\nFortran\nComputational Electromagnetics\n计算电磁学\n\n\n554.roms_r\n654.roms_s\nFortran\nRegional ocean modeling\n区域海洋建模\n\n\nhttps://www.spec.org/cpu2017/results/res2017q2/cpu2017-20161026-00003.html\n\n预期结果：性能测试得分符合预期范围，无异常性能下降。\n\n\n3.1.4 稳定性与压力测试\n测试目的：验证CPU在高负载、长时间运行下的稳定性和可靠性，确保无死机、重启、MCE错误等问题。\n测试方法：\n运行长时间的CPU压力测试（通常24小时以上）。\n在压力测试期间，监控系统日志和硬件错误日志。\n\n\n\n测试工具：stress-ng、Prime95 (mprime)、Linpack。\n预期结果：在长时间压力测试下，系统运行稳定，无崩溃、重启或硬件错误记录。\n\n3.1.5 温度与功耗监控\n测试目的：验证CPU在不同负载下的温度和功耗是否在正常范围内，并检查温控和节能机制是否有效。\n测试方法：\n在待机和满载状态下，通过BMC&#x2F;IPMI或操作系统工具读取CPU温度和功耗。\n验证CPU频率是否能根据负载动态调整（如睿频、降频）。\n\n\n\n测试工具：ipmitool sensor、lm-sensors、turbostat。\n\n123#常用命令ipmitool sdr list \n\n\n\n\n预期结果：CPU温度和功耗在设计规格内，温控和节能机制符合预期。\n\n3.2 内存（Memory）\n3.2.1 识别与容量检测3.2.2 带宽与延迟测试123456789101112#define    ONE            p = (char **)*p;#define    FIVE    ONE ONE ONE ONE ONE#define    TEN            FIVE FIVE#define    FIFTY    TEN TEN TEN TEN TEN#define    HUNDRED    FIFTY FIFTY    while (iterations-- &gt; 0) &#123;        for (i = 0; i &lt; count; ++i) &#123;            HUNDRED;        &#125;    &#125;\n\n\n\n3.2.3 ECC&#x2F;纠错功能3.2.4 稳定性与压力测试3.2.5 多通道&#x2F;多根条兼容性存储延迟 \n在处理器的性能指标中，各级Cache的访存延迟是一个重要的参数，其决定如果Cache访问命中或者失效，需要多少拍能回来，                       其为基于跳步（stride）的访存测试结果。\n这个测试应用LMbench中的存储延迟测试工具，执行的命令为.&#x2F;lat_mem_rd 128M 4096，其中4096参数为跳步大小。\n其基本原理是，通过按给定间隔去循环读一定大小的内存区域，测量每个读平均的时间。如果区域大小小于L1 Cache大小，时间应该接近L1的访问延迟；如果大于L1小于L2，则接近L2访问延迟；\n3.3 存储（硬盘&#x2F;SSD&#x2F;RAID）3.3.1 识别与容量检测3.3.2 性能测试3.3.3 RAID功能与容错3.3.4 热插拔与重建3.3.5 数据完整性与恢复3.4 网络（NIC&#x2F;网卡）3.4.1 识别与速率检测3.4.2 单口&#x2F;多口带宽测试3.4.3 多队列与中断亲和性3.4.4 直连&#x2F;组网功能3.4.5 PXE&#x2F;远程启动3.5 主板与芯片组3.5.1 识别与信息检测3.5.2 BIOS&#x2F;UEFI功能与升级3.5.3 PCIe插槽与扩展卡兼容性3.5.4 温度与电压监控3.6 电源与风扇3.6.1 电源冗余与切换3.6.2 风扇转速与温控3.6.3 功耗测试3.6.4 断电&#x2F;恢复3.7 BMC&#x2F;IPMI&#x2F;远程管理3.7.1 远程管理功能3.7.2 传感器与告警3.7.3 虚拟介质与远程控制3.7.4 固件升级与恢复3.8 GPU&#x2F;加速卡3.8.1 识别与驱动加载3.8.2 性能与兼容性3.8.3 稳定性与压力测试3.9 其他部件3.9.1 USB&#x2F;串口&#x2F;并口3.9.2 TPM&#x2F;安全模块3.9.3 光驱&#x2F;读卡器等4. 整机维度测试4.1 操作系统与驱动4.1.1 操作系统安装与兼容性4.1.2 驱动加载与兼容性4.1.3 固件升级与回滚4.1.4 日志与告警检测4.2 性能测试4.2.1 CPU整机性能计算机系统的性能有许多衡量指标，如执行时间或者响应时间、吞吐率、加速比、每条指令的时钟周期数（CPI）、每秒执行百万条指令数（MIPS）、每秒执行百万浮点运算数（MFLOPS）、每秒执行的事务数（TPS）和归一化的执行时间等。\n归根结底，计算机的性能最本质的定义是“完成一个任务所需要的时间”。\n计算机中完成一个任务的时间包括CPU计算、磁盘的访问、内存的访问、输入输出的活动和操作系统的开销等所有的时间。\n4.2.2 内存整机带宽与延迟4.2.3 存储整机性能4.2.4 网络整机带宽与延迟4.2.5 整机压力测试4.3 稳定性与可靠性4.3.1 长时间压力测试4.3.2 断电&#x2F;重启&#x2F;热插拔4.3.3 多用户并发4.3.4 软硬件容错4.4 功耗与能耗4.4.1 待机功耗4.4.2 满载功耗4.4.3 节能特性4.5 安全性4.5.1 账户与权限管理4.5.2 防火墙与端口安全4.5.3 日志与审计4.5.4 恶意代码与漏洞扫描4.6 兼容性与互操作性4.6.1 多操作系统兼容4.6.2 多种存储&#x2F;网络设备兼容4.6.3 虚拟化兼容4.7 故障注入与恢复4.7.1 硬件故障模拟4.7.2 软件异常处理4.7.3 数据恢复能力5. 测试结果与问题记录5.1 测试结果汇总5.2 问题与缺陷记录5.3 解决建议6.附录6.1 测试脚本与工具说明\n\n\nspeccpu2017\n1.1.8\nCPU性能测试工具\n商用软件，需官方购买\n\n\n\nstream\n&#x2F;\n内存带宽性能测试工具\nhttps://github.com/jeffhammond/STREAM/archive/master.zip\n\n\nFIO\n3.13\n磁盘IO性能测试工具\nhttps://brick.kernel.dk/snaps/fio-3.33.tar.gz\n\n\nnetperf\n2.7.0\n网络带宽性能测试工具\nhttps://github.com/HewlettPackard/netperf/archive/netperf-2.7.0.tar.gz\n\n\nIperf\n\n\n\n\n\nstress\n1.0.5\n稳定性压力测试软件\nhttps://fossies.org/linux/privat/old/stress-1.0.5.tar.gz\n\n\nMemtester\n\n\n\n\n\n\n\n\n\n\n\n6.2 术语表AI 人工智能（Artificial Intelligence）AIGC 生成式人工智能（Artificial Intelligence Generated Content）ASIC 专用集成电路芯片（Application Specific Integrated Circuit）CEM 板卡机电（Card Electromechanical）CPU 中央处理器（Central Processing Unit）EMC 电磁兼容性（Electromagnetic Compatibility）FPGA 现场可编程门阵列（Field Programmable Gate Array）GPGPU 通用图像处理器（General-purpose computing on graphics processing units）PCIe 高速外围组件互连总线 （Peripheral Component Interconnect Express）PUE 数据中心电能利用率（Power Usage Effectiveness）RCM 机柜冷却工质供回歧管（Rack Coolant Manifold）VR 电压调节器（Voltage Regulator）\n6.3 参考文献","slug":"服务器测试一本通","date":"2025-05-22T15:19:39.000Z","categories_index":"Tech,AI Infra","tags_index":"server","author_index":"Rocky Liu"},{"id":"96423f47dcfebc491f331e94a810e37a","title":"服务器-JDM模式","content":"退一步显然没有海阔天空，但进一步也没有成熟经验。在此之前，科技产业只有两种IT供应链模式：“产品型”的OEM和“定制型”的ODM。前者是我（设备供应商）卖什么，你就只能买什么；后者是我（甲方客户）买什么，你就只能卖什么。\nJDM模式全称是Joint Design Manufacture联合开发模式\n","slug":"服务器-JDM模式","date":"2025-05-15T13:55:21.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"e2583dcf1cc815d60f007cec0201c0b7","title":"LLM_Interview_Note","content":"1.当训练推理卡规模倍增的情况下，最容易产生瓶颈的位置可能是什么？a.请展开分析产生的原因b.对于此类问题，有什么优化或者缓解的方案LLM训练&amp;推理相关问题\n\n当训练推理卡规模倍增的情况下，最容易产生瓶颈的位置可能是什么？a. 请展开分析产生的原因b. 对于此类问题，有什么优化或者缓解方案● 主要瓶颈位置及原因\n网络通信带宽瓶颈当训练推理卡规模倍增时，网络通信往往成为首要瓶颈。在分布式训练中，每个GPU完成计算后需与其他设备交换梯度信息，形成全局更新。随着设备数量增加，通信量可能呈平方或线性增长，而网络基础设施提升通常不成比例。这导致大量GPU在计算完成后需等待梯度同步，显著降低整体训练效率。特别是在大批量训练时，梯度同步时间可能占据总训练时间的30%以上。\n\n2.内存带宽瓶颈现代GPU计算核心数量增长速度通常快于内存带宽提升。在大模型训练过程中，权重、激活值、梯度等数据需在内存与计算单元间频繁传输，内存带宽不足会造成”内存墙”问题。测试表明，大型模型训练时GPU计算核心利用率可能仅有40-60%，主要受限于内存带宽，而非计算能力。这种情况下，即使增加更多GPU，性能提升也会低于理想值。\n3.存储I&#x2F;O瓶颈大规模训练通常需处理TB级甚至PB级数据集。当并行GPU数量成倍增加时，对存储系统的并发读取压力呈线性增长。传统存储架构难以满足数百上千GPU的并发读取需求，导致数据加载成为训练流水线中的瓶颈。实践表明，在某些大规模训练中，GPU可能有20-30%时间处于等待数据状态。\n4.电力和散热瓶颈\t高性能GPU&#x2F;TPU功耗通常在300-700W范围，密集部署时每机柜功耗可达40-60kW，远超传统数据中心设计标准(~15kW&#x2F;机柜)。此外，空气冷却效率有限，难以有效散走如此密集的热量。在功率或温度限制下，GPU&#x2F;TPU可能被迫降频运行，无法发挥全部性能潜力。\n5.软件扩展性瓶颈\t许多训练框架最初设计时未考虑极大规模并行场景。随着设备数量增加，调度开销、负载不均衡、资源碎片化等问题变得更为突出。软件层面的低效率可能使硬件资源利用率下降到理想值的70%以下，且这种效率损失通常随规模增大而加剧。\n● 优化与缓解方案\n\n网络通信优化 高性能互联技术：部署InfiniBand HDR&#x2F;NDR、RDMA或专用AI网络架构，提供高带宽低延迟网络(如400Gbps-800Gbps互联)高效通信算法：实施Ring AllReduce、Tree AllReduce、BytePS等集合通信算法，降低通信复杂度梯度压缩技术：采用量化(1-8bit)、Top-K稀疏化、错误补偿等方法减少传输数据量通信计算重叠：设计流水线使梯度通信与下一步计算并行执行，减少等待时间2.内存带宽优化混合精度训练：使用FP16&#x2F;BF16替代FP32，在保持精度的同时减少内存传输量达50%梯度累积策略：增大逻辑批次大小但分步计算，减少参数更新和同步频率内存效率算法：实施激活值重计算(Activation Recomputation)、选择性检查点(Selective Checkpointing)等节省内存技术硬件选择优化：优先选用HBM2E&#x2F;HBM3等高带宽内存的GPU&#x2F;TPU，如NVIDIA H100&#x2F;H200或AMD MI300系列\n\n存储I&#x2F;O优化高性能分布式存储：部署HDFS、Lustre、Ceph或专用AI存储系统，提供TB&#x2F;s级吞吐量多级缓存架构：在计算节点本地SSD或内存中建立数据缓存层，减少远程访问智能数据预取：基于训练模式预测并提前加载下一批训练数据，隐藏I&#x2F;O延迟高效数据流水线：实现多阶段并行数据处理，如NVIDIA DALI或TensorFlow tf.data优化流水线\n\n电力和散热解决方案先进冷却技术：采用直接液冷、浸没式冷却或冷板技术，散热效率提升3-5倍高效电源系统：使用转换效率95%以上的电源和UPS系统，减少能耗转换损失智能功耗管理：实施动态电压频率调节(DVFS)和精细化功耗分配，优化整体能效专用AI基础设施：建设专为高密度AI集群设计的数据中心，支持100kW+每机柜功率\n\n软件架构优化专业分布式框架：使用DeepSpeed、Megatron-LM、Colossal-AI等专为大规模训练设计的框架混合并行策略：结合数据并行、模型并行、流水线并行和张量并行等技术，最大化硬件利用率ZeRO优化系列：实施ZeRO-Offload、ZeRO-Infinity等内存优化技术，突破单卡内存限制容错训练系统：支持检查点、弹性恢复和动态资源调整的训练系统，提高大规模集群可靠性\n\n\n三、综合优化策略最有效的方案通常是综合应用上述技术，形成完整优化体系：基础设施层面：建设专用AI训练集群，配备高带宽网络、液冷系统和高效电源硬件选型层面：选择内存带宽与计算能力平衡的加速卡，如H100、H200或专用ASIC系统软件层面：部署优化的驱动、通信库和分布式文件系统，提供底层效率保障训练框架层面：使用支持多种并行策略的框架，根据模型特点选择最佳并行方案算法优化层面：实施混合精度、梯度压缩、激活值重计算等算法级优化通过这种多层次、全方位的优化体系，可以显著提高大规模推理卡训练效率，使性能扩展更接近线性理想状态，充分发挥硬件投资价值。在实践中，通常需根据具体模型特点、训练规模和可用资源，定制最适合的优化组合。2.请解释并介绍一下Roofline模型，如何判断性能已经达到计算瓶颈\n3.请介绍一下Flash-attention&#x2F;Page attention\n4.当进行GEMM计算时，一定可以保证它是一个计算瓶颈的算子？优化思路如何？\n5.对于性能优化的定位和瓶颈的检测\n6.GQA attention模块的实现\n7.什么是scaling law\n8.模型结构\n9.解决显存容量不够的方法，对于显存优化的选择有什么看法？\n10.MOE 和Dense模型的区别 各自的优缺点a.计算量、参数量、训练效果b.如何选择\n11.宏观上推理prefill、decode过程 prefill是compute bound、decode是memory bound\n12.算子gemm、transpose、mha、rmsnorm、gemv、rope等算子的优化方案\n13.量化awq&#x2F;fp8&#x2F;bf16&#x2F;int8&#x2F;gptq&#x2F;wight-only优化\n14.分布式推理 DP TP PP \n15.推理优化 continuous batching&#x2F;speculative decoding \n16.分布式推理all-reduce&#x2F;all-gather 优化\n17.通信优化nccl infiniband优化\n","slug":"LLM-Interview-Note","date":"2025-05-14T14:27:14.000Z","categories_index":"","tags_index":"","author_index":"Rocky Liu"},{"id":"ea2193b2d8e3f686dcc9efed113a3d25","title":"我的450MT提车日记","content":"初识450mt 标准版\n“我妄想骑着我的烂摩托，去转一转…”，买摩托的想法从2023开始，一直想搞一辆摩托骑；于是在24年初报考了驾校，将驾驶证转到了北京，经历了一个月的忙碌，刘师傅终于可以合法上路了，奈何没有车；那下一步就是买车？又陷入了选择困难，虽然年轻人都喜欢仿赛（骑最猛的车，割最大的痔疮 哈哈），巡航那更不行（咖啡太苦，上班喝喝还行…)，所以对于一个豫西小伙来说，看惯山山水水，骨子里还是有点冒险精神，那最后只有ADV了，毕竟（Adventure Begins Where The Road Ends.），那就开整呗~开整肯定没那那么快，必须先考察一波。每天晚饭日常遛弯的首要任务就是看车，瞧瞧大佬都买什么车，看了一圈Kwaisake nijia400不下10辆（都是rich man）,啥配色都有；其次就是巡航，咖啡车还是上档次，占停车场半壁江山；ADV瞅了一圈，都不咋喜欢，主要排量太大腿短驾驭不了。总结一下，有点乱花渐欲迷人眼了,没我的梦中情车，看来还要寻觅一番…这里搞几张大佬爱车帅照，搞个简易车展…\n\n    .cekqqeaagoau{zoom:20%;}\n    .acsxpmpfqisg{zoom:20%;}\n    .wpkcaycxrwfh{zoom:20%;}\n    .xnnfdnnxhtvf{zoom:20%;}\n    .otsufpkgmvts{zoom:20%;}\n    .zohykxoowtom{zoom:20%;}\n\n\n\n\n\n","slug":"我的450MT提车日记","date":"2025-04-28T16:24:14.000Z","categories_index":"Life,Motocycle","tags_index":"","author_index":"Rocky Liu"}]