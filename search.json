[{"title":"服务器-JDM模式","url":"/2025/05/15/服务器-JDM模式/","content":"\n退一步显然没有海阔天空，但进一步也没有成熟经验。在此之前，科技产业只有两种IT供应链模式：“产品型”的OEM和“定制型”的ODM。前者是我（设备供应商）卖什么，你就只能买什么；后者是我（甲方客户）买什么，你就只能卖什么。\n\nJDM模式全称是Joint Design Manufacture联合开发模式"},{"title":"LLM_Interview_Note","url":"/2025/05/14/LLM-Interview-Note/","content":"\n1.当训练推理卡规模倍增的情况下，最容易产生瓶颈的位置可能是什么？\na.请展开分析产生的原因\nb.对于此类问题，有什么优化或者缓解的方案\nLLM训练&推理相关问题\n1. 当训练推理卡规模倍增的情况下，最容易产生瓶颈的位置可能是什么？\na. 请展开分析产生的原因\nb. 对于此类问题，有什么优化或者缓解方案\n● 主要瓶颈位置及原因\n1. 网络通信带宽瓶颈\n当训练推理卡规模倍增时，网络通信往往成为首要瓶颈。在分布式训练中，每个GPU完成计算后需与其他设备交换梯度信息，形成全局更新。随着设备数量增加，通信量可能呈平方或线性增长，而网络基础设施提升通常不成比例。这导致大量GPU在计算完成后需等待梯度同步，显著降低整体训练效率。特别是在大批量训练时，梯度同步时间可能占据总训练时间的30%以上。\n\n2.内存带宽瓶颈\n现代GPU计算核心数量增长速度通常快于内存带宽提升。在大模型训练过程中，权重、激活值、梯度等数据需在内存与计算单元间频繁传输，内存带宽不足会造成\"内存墙\"问题。测试表明，大型模型训练时GPU计算核心利用率可能仅有40-60%，主要受限于内存带宽，而非计算能力。这种情况下，即使增加更多GPU，性能提升也会低于理想值。\n\n3.存储I/O瓶颈\n大规模训练通常需处理TB级甚至PB级数据集。当并行GPU数量成倍增加时，对存储系统的并发读取压力呈线性增长。传统存储架构难以满足数百上千GPU的并发读取需求，导致数据加载成为训练流水线中的瓶颈。实践表明，在某些大规模训练中，GPU可能有20-30%时间处于等待数据状态。\n\n4.电力和散热瓶颈\n\t高性能GPU/TPU功耗通常在300-700W范围，密集部署时每机柜功耗可达40-60kW，远超传统数据中心设计标准(~15kW/机柜)。此外，空气冷却效率有限，难以有效散走如此密集的热量。在功率或温度限制下，GPU/TPU可能被迫降频运行，无法发挥全部性能潜力。\n\n5.软件扩展性瓶颈\n\t许多训练框架最初设计时未考虑极大规模并行场景。随着设备数量增加，调度开销、负载不均衡、资源碎片化等问题变得更为突出。软件层面的低效率可能使硬件资源利用率下降到理想值的70%以下，且这种效率损失通常随规模增大而加剧。\n\n● 优化与缓解方案\n 1. 网络通信优化\n     高性能互联技术：部署InfiniBand HDR/NDR、RDMA或专用AI网络架构，提供高带宽低延迟网络(如400Gbps-800Gbps互联)\n高效通信算法：实施Ring AllReduce、Tree AllReduce、BytePS等集合通信算法，降低通信复杂度\n梯度压缩技术：采用量化(1-8bit)、Top-K稀疏化、错误补偿等方法减少传输数据量\n通信计算重叠：设计流水线使梯度通信与下一步计算并行执行，减少等待时间\n2.内存带宽优化\n混合精度训练：使用FP16/BF16替代FP32，在保持精度的同时减少内存传输量达50%\n梯度累积策略：增大逻辑批次大小但分步计算，减少参数更新和同步频率\n内存效率算法：实施激活值重计算(Activation Recomputation)、选择性检查点(Selective Checkpointing)等节省内存技术\n硬件选择优化：优先选用HBM2E/HBM3等高带宽内存的GPU/TPU，如NVIDIA H100/H200或AMD MI300系列\n3. 存储I/O优化\n高性能分布式存储：部署HDFS、Lustre、Ceph或专用AI存储系统，提供TB/s级吞吐量\n多级缓存架构：在计算节点本地SSD或内存中建立数据缓存层，减少远程访问\n智能数据预取：基于训练模式预测并提前加载下一批训练数据，隐藏I/O延迟\n高效数据流水线：实现多阶段并行数据处理，如NVIDIA DALI或TensorFlow tf.data优化流水线\n\n4. 电力和散热解决方案\n先进冷却技术：采用直接液冷、浸没式冷却或冷板技术，散热效率提升3-5倍\n高效电源系统：使用转换效率95%以上的电源和UPS系统，减少能耗转换损失\n智能功耗管理：实施动态电压频率调节(DVFS)和精细化功耗分配，优化整体能效\n专用AI基础设施：建设专为高密度AI集群设计的数据中心，支持100kW+每机柜功率\n5. 软件架构优化\n专业分布式框架：使用DeepSpeed、Megatron-LM、Colossal-AI等专为大规模训练设计的框架\n混合并行策略：结合数据并行、模型并行、流水线并行和张量并行等技术，最大化硬件利用率\nZeRO优化系列：实施ZeRO-Offload、ZeRO-Infinity等内存优化技术，突破单卡内存限制\n容错训练系统：支持检查点、弹性恢复和动态资源调整的训练系统，提高大规模集群可靠性\n\n三、综合优化策略\n最有效的方案通常是综合应用上述技术，形成完整优化体系：\n基础设施层面：建设专用AI训练集群，配备高带宽网络、液冷系统和高效电源\n硬件选型层面：选择内存带宽与计算能力平衡的加速卡，如H100、H200或专用ASIC\n系统软件层面：部署优化的驱动、通信库和分布式文件系统，提供底层效率保障\n训练框架层面：使用支持多种并行策略的框架，根据模型特点选择最佳并行方案\n算法优化层面：实施混合精度、梯度压缩、激活值重计算等算法级优化\n通过这种多层次、全方位的优化体系，可以显著提高大规模推理卡训练效率，使性能扩展更接近线性理想状态，充分发挥硬件投资价值。在实践中，通常需根据具体模型特点、训练规模和可用资源，定制最适合的优化组合。\n2.请解释并介绍一下Roofline模型，如何判断性能已经达到计算瓶颈\n\n3.请介绍一下Flash-attention/Page attention\n\n4.当进行GEMM计算时，一定可以保证它是一个计算瓶颈的算子？优化思路如何？\n\n5.对于性能优化的定位和瓶颈的检测\n\n6.GQA attention模块的实现\n\n7.什么是scaling law\n\n8.模型结构\n\n9.解决显存容量不够的方法，对于显存优化的选择有什么看法？\n\n10.MOE 和Dense模型的区别 各自的优缺点 \na.计算量、参数量、训练效果\nb.如何选择\n\n11.宏观上推理prefill、decode过程 prefill是compute bound、decode是memory bound\n\n12.算子gemm、transpose、mha、rmsnorm、gemv、rope等算子的优化方案\n\n13.量化awq/fp8/bf16/int8/gptq/wight-only优化\n\n14.分布式推理 DP TP PP \n\n15.推理优化 continuous batching/speculative decoding \n\n16.分布式推理all-reduce/all-gather 优化\n\n17.通信优化nccl infiniband优化\n\n"},{"title":"Hello World","url":"/2025/05/14/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"我的450MT提车日记","url":"/2025/04/29/我的450MT提车日记/","content":"\n## 初识\n450mt 标准版\n\n\"我妄想骑着我的烂摩托，去转一转...\"，买摩托的想法从2023开始，一直想搞一辆摩托骑；于是在24年初报考了驾校，将驾驶证转到了北京，经历了一个月的忙碌，刘师傅终于可以合法上路了，奈何没有车；那下一步就是买车？又陷入了选择困难，虽然年轻人都喜欢仿赛（骑最猛的车，割最大的痔疮 哈哈），巡航那更不行（咖啡太苦，上班喝喝还行...)，所以对于一个豫西小伙来说，看惯山山水水，骨子里还是有点冒险精神，那最后只有ADV了，毕竟（Adventure Begins Where The Road Ends.），那就开整呗~\n开整肯定没那那么快，必须先考察一波。每天晚饭日常遛弯的首要任务就是看车，瞧瞧大佬都买什么车，看了一圈Kwaisake nijia400不下10辆（都是rich man）,啥配色都有；其次就是巡航，咖啡车还是上档次，占停车场半壁江山；ADV瞅了一圈，都不咋喜欢，主要排量太大腿短驾驭不了。总结一下，有点乱花渐欲迷人眼了,没我的梦中情车，看来还要寻觅一番...\n这里搞几张大佬爱车帅照，搞个简易车展...\n\n<center class=\"half\">\n    <img src=\"我的450MT提车日记/kwaisak.jpg\" alt=\"kwaisak\" style=\"zoom:20%;\" />\n    <img src=\"我的450MT提车日记/BMW1800.jpg\" alt=\"BMW1800\" style=\"zoom:20%;\" />\n    <img src=\"我的450MT提车日记/Kawasaki.jpg\" alt=\"Kawasaki\" style=\"zoom:20%;\" />\n    <img src=\"我的450MT提车日记/ktm390ADV.jpg\" alt=\"ktm390ADV\" style=\"zoom:20%;\" />\n    <img src=\"我的450MT提车日记/aplia.jpg\" alt=\"aplia\" style=\"zoom:20%;\" />\n    <img src=\"我的450MT提车日记/xiaoche.jpg\" alt=\"xiaoche\" style=\"zoom:20%;\" />\n</center>\n\n![450mt](我的450MT提车日记/450mt.png)\n\n\n![450mt](我的450MT提车日记/450mt.png)\n\n![450mt](我的450MT提车日记/450mt.png)"}]